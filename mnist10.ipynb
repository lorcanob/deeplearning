{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "import torch\n",
    "\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "from fastbook import *\n",
    "path = Path('/storage/data/mnist_png')\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('training'),Path('testing')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ingest data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "num_dict = L(enumerate(num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [(0, 'zero'),(1, 'one'),(2, 'two'),(3, 'three'),(4, 'four'),(5, 'five'),(6, 'six'),(7, 'seven'),(8, 'eight'),(9, 'nine')],\n",
       " 'four')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "num_dict, num_dict[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackNums(train=True):\n",
    "    num_cats = [num_dict[num][1] for num in range(0,10)]\n",
    "    if train==True:\n",
    "        num_path = [(path/'training'/str(num[0])).ls().sorted() for num in num_dict]\n",
    "    else:\n",
    "        num_path = [(path/'testing'/str(num[0])).ls().sorted() for num in num_dict]\n",
    "    return num_cats, num_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat,num_path = stackNums()\n",
    "valid_num_cat,valid_num_path = stackNums(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['zero',\n",
       "  'one',\n",
       "  'two',\n",
       "  'three',\n",
       "  'four',\n",
       "  'five',\n",
       "  'six',\n",
       "  'seven',\n",
       "  'eight',\n",
       "  'nine'],\n",
       " [(#5923) [Path('training/0/1.png'),Path('training/0/1000.png'),Path('training/0/10005.png'),Path('training/0/10010.png'),Path('training/0/10022.png'),Path('training/0/10025.png'),Path('training/0/10026.png'),Path('training/0/10045.png'),Path('training/0/10069.png'),Path('training/0/10071.png')...],\n",
       "  (#6742) [Path('training/1/10006.png'),Path('training/1/10007.png'),Path('training/1/1002.png'),Path('training/1/10020.png'),Path('training/1/10027.png'),Path('training/1/1003.png'),Path('training/1/10040.png'),Path('training/1/10048.png'),Path('training/1/10058.png'),Path('training/1/10067.png')...],\n",
       "  (#5958) [Path('training/2/10009.png'),Path('training/2/10016.png'),Path('training/2/10024.png'),Path('training/2/10029.png'),Path('training/2/10072.png'),Path('training/2/10073.png'),Path('training/2/10075.png'),Path('training/2/10078.png'),Path('training/2/10081.png'),Path('training/2/10082.png')...],\n",
       "  (#6131) [Path('training/3/10.png'),Path('training/3/10000.png'),Path('training/3/10011.png'),Path('training/3/10031.png'),Path('training/3/10034.png'),Path('training/3/10042.png'),Path('training/3/10052.png'),Path('training/3/1007.png'),Path('training/3/10074.png'),Path('training/3/10091.png')...],\n",
       "  (#5842) [Path('training/4/10013.png'),Path('training/4/10018.png'),Path('training/4/10033.png'),Path('training/4/1004.png'),Path('training/4/1006.png'),Path('training/4/10060.png'),Path('training/4/1008.png'),Path('training/4/10103.png'),Path('training/4/10104.png'),Path('training/4/10114.png')...],\n",
       "  (#5421) [Path('training/5/0.png'),Path('training/5/100.png'),Path('training/5/10008.png'),Path('training/5/10015.png'),Path('training/5/10030.png'),Path('training/5/10035.png'),Path('training/5/10049.png'),Path('training/5/10051.png'),Path('training/5/10056.png'),Path('training/5/10062.png')...],\n",
       "  (#5918) [Path('training/6/10017.png'),Path('training/6/10032.png'),Path('training/6/10036.png'),Path('training/6/10037.png'),Path('training/6/10044.png'),Path('training/6/10053.png'),Path('training/6/10076.png'),Path('training/6/10089.png'),Path('training/6/10101.png'),Path('training/6/10108.png')...],\n",
       "  (#6265) [Path('training/7/10002.png'),Path('training/7/1001.png'),Path('training/7/10014.png'),Path('training/7/10019.png'),Path('training/7/10039.png'),Path('training/7/10046.png'),Path('training/7/10050.png'),Path('training/7/10063.png'),Path('training/7/10077.png'),Path('training/7/10086.png')...],\n",
       "  (#5851) [Path('training/8/10001.png'),Path('training/8/10012.png'),Path('training/8/10021.png'),Path('training/8/10041.png'),Path('training/8/10054.png'),Path('training/8/10057.png'),Path('training/8/10061.png'),Path('training/8/10064.png'),Path('training/8/10066.png'),Path('training/8/10079.png')...],\n",
       "  (#5949) [Path('training/9/10003.png'),Path('training/9/10004.png'),Path('training/9/10023.png'),Path('training/9/10028.png'),Path('training/9/10038.png'),Path('training/9/10043.png'),Path('training/9/10047.png'),Path('training/9/1005.png'),Path('training/9/10055.png'),Path('training/9/10059.png')...]],\n",
       " [(#980) [Path('testing/0/10.png'),Path('testing/0/1001.png'),Path('testing/0/1009.png'),Path('testing/0/101.png'),Path('testing/0/1034.png'),Path('testing/0/1047.png'),Path('testing/0/1061.png'),Path('testing/0/1084.png'),Path('testing/0/1094.png'),Path('testing/0/1121.png')...],\n",
       "  (#1135) [Path('testing/1/1004.png'),Path('testing/1/1008.png'),Path('testing/1/1011.png'),Path('testing/1/1019.png'),Path('testing/1/1025.png'),Path('testing/1/1027.png'),Path('testing/1/1030.png'),Path('testing/1/1037.png'),Path('testing/1/1038.png'),Path('testing/1/1040.png')...],\n",
       "  (#1032) [Path('testing/2/1.png'),Path('testing/2/1002.png'),Path('testing/2/1016.png'),Path('testing/2/1031.png'),Path('testing/2/1036.png'),Path('testing/2/1049.png'),Path('testing/2/1050.png'),Path('testing/2/1053.png'),Path('testing/2/1056.png'),Path('testing/2/106.png')...],\n",
       "  (#1010) [Path('testing/3/1020.png'),Path('testing/3/1028.png'),Path('testing/3/1042.png'),Path('testing/3/1062.png'),Path('testing/3/1066.png'),Path('testing/3/1067.png'),Path('testing/3/1069.png'),Path('testing/3/1072.png'),Path('testing/3/1092.png'),Path('testing/3/1095.png')...],\n",
       "  (#982) [Path('testing/4/1010.png'),Path('testing/4/1015.png'),Path('testing/4/1023.png'),Path('testing/4/1024.png'),Path('testing/4/103.png'),Path('testing/4/1043.png'),Path('testing/4/1051.png'),Path('testing/4/1057.png'),Path('testing/4/1059.png'),Path('testing/4/1060.png')...],\n",
       "  (#892) [Path('testing/5/1003.png'),Path('testing/5/102.png'),Path('testing/5/1022.png'),Path('testing/5/1032.png'),Path('testing/5/1041.png'),Path('testing/5/1046.png'),Path('testing/5/1070.png'),Path('testing/5/1073.png'),Path('testing/5/1082.png'),Path('testing/5/1087.png')...],\n",
       "  (#958) [Path('testing/6/100.png'),Path('testing/6/1014.png'),Path('testing/6/1017.png'),Path('testing/6/1035.png'),Path('testing/6/1044.png'),Path('testing/6/1079.png'),Path('testing/6/1085.png'),Path('testing/6/1099.png'),Path('testing/6/11.png'),Path('testing/6/1106.png')...],\n",
       "  (#1028) [Path('testing/7/0.png'),Path('testing/7/1006.png'),Path('testing/7/1012.png'),Path('testing/7/1021.png'),Path('testing/7/1039.png'),Path('testing/7/1055.png'),Path('testing/7/1071.png'),Path('testing/7/1091.png'),Path('testing/7/1096.png'),Path('testing/7/1100.png')...],\n",
       "  (#974) [Path('testing/8/1007.png'),Path('testing/8/1018.png'),Path('testing/8/1026.png'),Path('testing/8/1029.png'),Path('testing/8/1033.png'),Path('testing/8/1052.png'),Path('testing/8/1068.png'),Path('testing/8/1074.png'),Path('testing/8/1093.png'),Path('testing/8/110.png')...],\n",
       "  (#1009) [Path('testing/9/1000.png'),Path('testing/9/1005.png'),Path('testing/9/1013.png'),Path('testing/9/104.png'),Path('testing/9/1045.png'),Path('testing/9/1048.png'),Path('testing/9/105.png'),Path('testing/9/1058.png'),Path('testing/9/1063.png'),Path('testing/9/108.png')...]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "num_cat,num_path,valid_num_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING LONG\n",
    "train_0s = torch.stack([tensor(Image.open(o)) for o in num_path[0]]).float()/255\n",
    "train_1s = torch.stack([tensor(Image.open(o)) for o in num_path[1]]).float()/255\n",
    "train_2s = torch.stack([tensor(Image.open(o)) for o in num_path[2]]).float()/255\n",
    "train_3s = torch.stack([tensor(Image.open(o)) for o in num_path[3]]).float()/255\n",
    "train_4s = torch.stack([tensor(Image.open(o)) for o in num_path[4]]).float()/255\n",
    "train_5s = torch.stack([tensor(Image.open(o)) for o in num_path[5]]).float()/255\n",
    "train_6s = torch.stack([tensor(Image.open(o)) for o in num_path[6]]).float()/255\n",
    "train_7s = torch.stack([tensor(Image.open(o)) for o in num_path[7]]).float()/255\n",
    "train_8s = torch.stack([tensor(Image.open(o)) for o in num_path[8]]).float()/255\n",
    "train_9s = torch.stack([tensor(Image.open(o)) for o in num_path[9]]).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Later consider using Pandas DataFrames as a means of sorting and assigning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING LONG\n",
    "valid_0s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[0]]).float()/255\n",
    "valid_1s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[1]]).float()/255\n",
    "valid_2s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[2]]).float()/255\n",
    "valid_3s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[3]]).float()/255\n",
    "valid_4s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[4]]).float()/255\n",
    "valid_5s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[5]]).float()/255\n",
    "valid_6s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[6]]).float()/255\n",
    "valid_7s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[7]]).float()/255\n",
    "valid_8s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[8]]).float()/255\n",
    "valid_9s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[9]]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5923, 28, 28]), torch.Size([1010, 28, 28]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "train_0s.shape, valid_3s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([train_0s, train_1s, train_2s, train_3s, train_4s, train_5s, train_6s, train_7s, train_8s, train_9s]).view(-1, 28*28)\n",
    "train_y = tensor([0]*len(train_0s) + [1]*len(train_1s) + [2]*len(train_2s) + [3]*len(train_3s) + [4]*len(train_4s) + [5]*len(train_5s) + [6]*len(train_6s) + [7]*len(train_7s) + [8]*len(train_8s) + [9]*len(train_9s)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_0s, valid_1s, valid_2s, valid_3s, valid_4s, valid_5s, valid_6s, valid_7s, valid_8s, valid_9s]).view(-1, 28*28)\n",
    "valid_y = tensor([0]*len(valid_0s) + [1]*len(valid_1s) + [2]*len(valid_2s) + [3]*len(valid_3s) + [4]*len(valid_4s) + [5]*len(valid_5s) + [6]*len(valid_6s) + [7]*len(valid_7s) + [8]*len(valid_8s) + [9]*len(valid_9s)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define architecture, parameters, loss, metrics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParam(size, std=0.5):\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "def mnistModel(inputs):\n",
    "    acts = inputs@w1 + b1\n",
    "    acts = acts.max(tensor(0.))\n",
    "    acts = acts@w2 + b2\n",
    "    return acts\n",
    "\n",
    "def mnistLoss(preds, targs): #softmax to CELoss\n",
    "    sm_preds = -torch.log(torch.softmax(preds, dim=1))\n",
    "    idx = range(10)\n",
    "    return sm_preds[idx,targs].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnistLoss(preds, yb)\n",
    "    loss.backward()\n",
    "    \n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "def batch_accuracy(xb, yb): #need to tweak this func to be relevant to multicat outputs\n",
    "    sm_preds = -torch.log(torch.softmax(xb, dim=1))\n",
    "    pred_idx = range(16) #Why is sm_preds length 16, not 256? \"index 16 is out of bounds for dimension 0 with size 16\"\n",
    "    correct = [sm_preds[entry].max() == sm_preds[entry,yb[entry]] for entry in pred_idx] #Are these nested indexs a bad idea\n",
    "    return torch.Tensor(correct).float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise parameters and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = initParam((28*28,30))\n",
    "b1 = initParam(30)\n",
    "w2 = initParam((30,10))\n",
    "b2 = initParam(10)\n",
    "lr = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim((w1,b1,w2,b2), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 16 is out of bounds for dimension 0 with size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-747471ac3ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnistModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-264-d96d6eed6634>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-264-d96d6eed6634>\u001b[0m in \u001b[0;36mvalidate_epoch\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-264-d96d6eed6634>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-264-d96d6eed6634>\u001b[0m in \u001b[0;36mbatch_accuracy\u001b[0;34m(xb, yb)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msm_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpred_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Why do I get an error when this is 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msm_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msm_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-264-d96d6eed6634>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msm_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpred_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Why do I get an error when this is 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msm_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msm_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 16 is out of bounds for dimension 0 with size 16"
     ]
    }
   ],
   "source": [
    "train_model(mnistModel, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "max??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test cell\n",
    "acts1 = xb@w1 + b1\n",
    "acts2 = acts1.max(tensor(0.0))\n",
    "acts3 = acts2@w2 + b2 #does this layer need to return a [256,10]\n",
    "\n",
    "sm_preds = -torch.log(torch.softmax(acts3, dim=1))\n",
    "pred_idx = range(256)\n",
    "cat_idx = range(10)\n",
    "\n",
    "#figure out if the shapes of the tensors through the model are correct. Then regularise the activations to stop over/under\n",
    "#Regularisation/Weight decay can be found in 08_collab\n",
    "\n",
    "#xb.size()\n",
    "#acts3\n",
    "#torch.softmax(acts3, dim=0)[29]\n",
    "#torch.log(torch.softmax(acts3, dim=0))[29]\n",
    "\n",
    "#sm_preds[19].long()\n",
    "correct = torch.Tensor([sm_preds[entry].max() == sm_preds[entry,yb[entry]] for entry in pred_idx]) #select sm_preds.max() == sm_preds[id]?\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test cell\n",
    "torch.random.manual_seed(42);\n",
    "testact = torch.randn((6,2))*2\n",
    "testact.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.5235, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test cell\n",
    "#mnist10\n",
    "preds = mnistModel(xb)\n",
    "\n",
    "mnistLoss(preds, yb).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
