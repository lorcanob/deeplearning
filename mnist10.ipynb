{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "import torch\n",
    "\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "from fastbook import *\n",
    "path = Path('/storage/data/mnist_png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ingest data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "num_dict = L(enumerate(num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [(0, 'zero'),(1, 'one'),(2, 'two'),(3, 'three'),(4, 'four'),(5, 'five'),(6, 'six'),(7, 'seven'),(8, 'eight'),(9, 'nine')],\n",
       " 'four')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "num_dict, num_dict[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackNums(train=True):\n",
    "    num_cats = [num_dict[num][1] for num in range(0,10)]\n",
    "    if train==True:\n",
    "        num_path = [(path/'training'/str(num[0])).ls().sorted() for num in num_dict]\n",
    "    else:\n",
    "        num_path = [(path/'testing'/str(num[0])).ls().sorted() for num in num_dict]\n",
    "    return num_cats, num_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat,num_path = stackNums()\n",
    "valid_num_cat,valid_num_path = stackNums(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['zero',\n",
       "  'one',\n",
       "  'two',\n",
       "  'three',\n",
       "  'four',\n",
       "  'five',\n",
       "  'six',\n",
       "  'seven',\n",
       "  'eight',\n",
       "  'nine'],\n",
       " [(#5923) [Path('/storage/data/mnist_png/training/0/1.png'),Path('/storage/data/mnist_png/training/0/1000.png'),Path('/storage/data/mnist_png/training/0/10005.png'),Path('/storage/data/mnist_png/training/0/10010.png'),Path('/storage/data/mnist_png/training/0/10022.png'),Path('/storage/data/mnist_png/training/0/10025.png'),Path('/storage/data/mnist_png/training/0/10026.png'),Path('/storage/data/mnist_png/training/0/10045.png'),Path('/storage/data/mnist_png/training/0/10069.png'),Path('/storage/data/mnist_png/training/0/10071.png')...],\n",
       "  (#6742) [Path('/storage/data/mnist_png/training/1/10006.png'),Path('/storage/data/mnist_png/training/1/10007.png'),Path('/storage/data/mnist_png/training/1/1002.png'),Path('/storage/data/mnist_png/training/1/10020.png'),Path('/storage/data/mnist_png/training/1/10027.png'),Path('/storage/data/mnist_png/training/1/1003.png'),Path('/storage/data/mnist_png/training/1/10040.png'),Path('/storage/data/mnist_png/training/1/10048.png'),Path('/storage/data/mnist_png/training/1/10058.png'),Path('/storage/data/mnist_png/training/1/10067.png')...],\n",
       "  (#5958) [Path('/storage/data/mnist_png/training/2/10009.png'),Path('/storage/data/mnist_png/training/2/10016.png'),Path('/storage/data/mnist_png/training/2/10024.png'),Path('/storage/data/mnist_png/training/2/10029.png'),Path('/storage/data/mnist_png/training/2/10072.png'),Path('/storage/data/mnist_png/training/2/10073.png'),Path('/storage/data/mnist_png/training/2/10075.png'),Path('/storage/data/mnist_png/training/2/10078.png'),Path('/storage/data/mnist_png/training/2/10081.png'),Path('/storage/data/mnist_png/training/2/10082.png')...],\n",
       "  (#6131) [Path('/storage/data/mnist_png/training/3/10.png'),Path('/storage/data/mnist_png/training/3/10000.png'),Path('/storage/data/mnist_png/training/3/10011.png'),Path('/storage/data/mnist_png/training/3/10031.png'),Path('/storage/data/mnist_png/training/3/10034.png'),Path('/storage/data/mnist_png/training/3/10042.png'),Path('/storage/data/mnist_png/training/3/10052.png'),Path('/storage/data/mnist_png/training/3/1007.png'),Path('/storage/data/mnist_png/training/3/10074.png'),Path('/storage/data/mnist_png/training/3/10091.png')...],\n",
       "  (#5842) [Path('/storage/data/mnist_png/training/4/10013.png'),Path('/storage/data/mnist_png/training/4/10018.png'),Path('/storage/data/mnist_png/training/4/10033.png'),Path('/storage/data/mnist_png/training/4/1004.png'),Path('/storage/data/mnist_png/training/4/1006.png'),Path('/storage/data/mnist_png/training/4/10060.png'),Path('/storage/data/mnist_png/training/4/1008.png'),Path('/storage/data/mnist_png/training/4/10103.png'),Path('/storage/data/mnist_png/training/4/10104.png'),Path('/storage/data/mnist_png/training/4/10114.png')...],\n",
       "  (#5421) [Path('/storage/data/mnist_png/training/5/0.png'),Path('/storage/data/mnist_png/training/5/100.png'),Path('/storage/data/mnist_png/training/5/10008.png'),Path('/storage/data/mnist_png/training/5/10015.png'),Path('/storage/data/mnist_png/training/5/10030.png'),Path('/storage/data/mnist_png/training/5/10035.png'),Path('/storage/data/mnist_png/training/5/10049.png'),Path('/storage/data/mnist_png/training/5/10051.png'),Path('/storage/data/mnist_png/training/5/10056.png'),Path('/storage/data/mnist_png/training/5/10062.png')...],\n",
       "  (#5918) [Path('/storage/data/mnist_png/training/6/10017.png'),Path('/storage/data/mnist_png/training/6/10032.png'),Path('/storage/data/mnist_png/training/6/10036.png'),Path('/storage/data/mnist_png/training/6/10037.png'),Path('/storage/data/mnist_png/training/6/10044.png'),Path('/storage/data/mnist_png/training/6/10053.png'),Path('/storage/data/mnist_png/training/6/10076.png'),Path('/storage/data/mnist_png/training/6/10089.png'),Path('/storage/data/mnist_png/training/6/10101.png'),Path('/storage/data/mnist_png/training/6/10108.png')...],\n",
       "  (#6265) [Path('/storage/data/mnist_png/training/7/10002.png'),Path('/storage/data/mnist_png/training/7/1001.png'),Path('/storage/data/mnist_png/training/7/10014.png'),Path('/storage/data/mnist_png/training/7/10019.png'),Path('/storage/data/mnist_png/training/7/10039.png'),Path('/storage/data/mnist_png/training/7/10046.png'),Path('/storage/data/mnist_png/training/7/10050.png'),Path('/storage/data/mnist_png/training/7/10063.png'),Path('/storage/data/mnist_png/training/7/10077.png'),Path('/storage/data/mnist_png/training/7/10086.png')...],\n",
       "  (#5851) [Path('/storage/data/mnist_png/training/8/10001.png'),Path('/storage/data/mnist_png/training/8/10012.png'),Path('/storage/data/mnist_png/training/8/10021.png'),Path('/storage/data/mnist_png/training/8/10041.png'),Path('/storage/data/mnist_png/training/8/10054.png'),Path('/storage/data/mnist_png/training/8/10057.png'),Path('/storage/data/mnist_png/training/8/10061.png'),Path('/storage/data/mnist_png/training/8/10064.png'),Path('/storage/data/mnist_png/training/8/10066.png'),Path('/storage/data/mnist_png/training/8/10079.png')...],\n",
       "  (#5949) [Path('/storage/data/mnist_png/training/9/10003.png'),Path('/storage/data/mnist_png/training/9/10004.png'),Path('/storage/data/mnist_png/training/9/10023.png'),Path('/storage/data/mnist_png/training/9/10028.png'),Path('/storage/data/mnist_png/training/9/10038.png'),Path('/storage/data/mnist_png/training/9/10043.png'),Path('/storage/data/mnist_png/training/9/10047.png'),Path('/storage/data/mnist_png/training/9/1005.png'),Path('/storage/data/mnist_png/training/9/10055.png'),Path('/storage/data/mnist_png/training/9/10059.png')...]],\n",
       " [(#980) [Path('/storage/data/mnist_png/testing/0/10.png'),Path('/storage/data/mnist_png/testing/0/1001.png'),Path('/storage/data/mnist_png/testing/0/1009.png'),Path('/storage/data/mnist_png/testing/0/101.png'),Path('/storage/data/mnist_png/testing/0/1034.png'),Path('/storage/data/mnist_png/testing/0/1047.png'),Path('/storage/data/mnist_png/testing/0/1061.png'),Path('/storage/data/mnist_png/testing/0/1084.png'),Path('/storage/data/mnist_png/testing/0/1094.png'),Path('/storage/data/mnist_png/testing/0/1121.png')...],\n",
       "  (#1135) [Path('/storage/data/mnist_png/testing/1/1004.png'),Path('/storage/data/mnist_png/testing/1/1008.png'),Path('/storage/data/mnist_png/testing/1/1011.png'),Path('/storage/data/mnist_png/testing/1/1019.png'),Path('/storage/data/mnist_png/testing/1/1025.png'),Path('/storage/data/mnist_png/testing/1/1027.png'),Path('/storage/data/mnist_png/testing/1/1030.png'),Path('/storage/data/mnist_png/testing/1/1037.png'),Path('/storage/data/mnist_png/testing/1/1038.png'),Path('/storage/data/mnist_png/testing/1/1040.png')...],\n",
       "  (#1032) [Path('/storage/data/mnist_png/testing/2/1.png'),Path('/storage/data/mnist_png/testing/2/1002.png'),Path('/storage/data/mnist_png/testing/2/1016.png'),Path('/storage/data/mnist_png/testing/2/1031.png'),Path('/storage/data/mnist_png/testing/2/1036.png'),Path('/storage/data/mnist_png/testing/2/1049.png'),Path('/storage/data/mnist_png/testing/2/1050.png'),Path('/storage/data/mnist_png/testing/2/1053.png'),Path('/storage/data/mnist_png/testing/2/1056.png'),Path('/storage/data/mnist_png/testing/2/106.png')...],\n",
       "  (#1010) [Path('/storage/data/mnist_png/testing/3/1020.png'),Path('/storage/data/mnist_png/testing/3/1028.png'),Path('/storage/data/mnist_png/testing/3/1042.png'),Path('/storage/data/mnist_png/testing/3/1062.png'),Path('/storage/data/mnist_png/testing/3/1066.png'),Path('/storage/data/mnist_png/testing/3/1067.png'),Path('/storage/data/mnist_png/testing/3/1069.png'),Path('/storage/data/mnist_png/testing/3/1072.png'),Path('/storage/data/mnist_png/testing/3/1092.png'),Path('/storage/data/mnist_png/testing/3/1095.png')...],\n",
       "  (#982) [Path('/storage/data/mnist_png/testing/4/1010.png'),Path('/storage/data/mnist_png/testing/4/1015.png'),Path('/storage/data/mnist_png/testing/4/1023.png'),Path('/storage/data/mnist_png/testing/4/1024.png'),Path('/storage/data/mnist_png/testing/4/103.png'),Path('/storage/data/mnist_png/testing/4/1043.png'),Path('/storage/data/mnist_png/testing/4/1051.png'),Path('/storage/data/mnist_png/testing/4/1057.png'),Path('/storage/data/mnist_png/testing/4/1059.png'),Path('/storage/data/mnist_png/testing/4/1060.png')...],\n",
       "  (#892) [Path('/storage/data/mnist_png/testing/5/1003.png'),Path('/storage/data/mnist_png/testing/5/102.png'),Path('/storage/data/mnist_png/testing/5/1022.png'),Path('/storage/data/mnist_png/testing/5/1032.png'),Path('/storage/data/mnist_png/testing/5/1041.png'),Path('/storage/data/mnist_png/testing/5/1046.png'),Path('/storage/data/mnist_png/testing/5/1070.png'),Path('/storage/data/mnist_png/testing/5/1073.png'),Path('/storage/data/mnist_png/testing/5/1082.png'),Path('/storage/data/mnist_png/testing/5/1087.png')...],\n",
       "  (#958) [Path('/storage/data/mnist_png/testing/6/100.png'),Path('/storage/data/mnist_png/testing/6/1014.png'),Path('/storage/data/mnist_png/testing/6/1017.png'),Path('/storage/data/mnist_png/testing/6/1035.png'),Path('/storage/data/mnist_png/testing/6/1044.png'),Path('/storage/data/mnist_png/testing/6/1079.png'),Path('/storage/data/mnist_png/testing/6/1085.png'),Path('/storage/data/mnist_png/testing/6/1099.png'),Path('/storage/data/mnist_png/testing/6/11.png'),Path('/storage/data/mnist_png/testing/6/1106.png')...],\n",
       "  (#1028) [Path('/storage/data/mnist_png/testing/7/0.png'),Path('/storage/data/mnist_png/testing/7/1006.png'),Path('/storage/data/mnist_png/testing/7/1012.png'),Path('/storage/data/mnist_png/testing/7/1021.png'),Path('/storage/data/mnist_png/testing/7/1039.png'),Path('/storage/data/mnist_png/testing/7/1055.png'),Path('/storage/data/mnist_png/testing/7/1071.png'),Path('/storage/data/mnist_png/testing/7/1091.png'),Path('/storage/data/mnist_png/testing/7/1096.png'),Path('/storage/data/mnist_png/testing/7/1100.png')...],\n",
       "  (#974) [Path('/storage/data/mnist_png/testing/8/1007.png'),Path('/storage/data/mnist_png/testing/8/1018.png'),Path('/storage/data/mnist_png/testing/8/1026.png'),Path('/storage/data/mnist_png/testing/8/1029.png'),Path('/storage/data/mnist_png/testing/8/1033.png'),Path('/storage/data/mnist_png/testing/8/1052.png'),Path('/storage/data/mnist_png/testing/8/1068.png'),Path('/storage/data/mnist_png/testing/8/1074.png'),Path('/storage/data/mnist_png/testing/8/1093.png'),Path('/storage/data/mnist_png/testing/8/110.png')...],\n",
       "  (#1009) [Path('/storage/data/mnist_png/testing/9/1000.png'),Path('/storage/data/mnist_png/testing/9/1005.png'),Path('/storage/data/mnist_png/testing/9/1013.png'),Path('/storage/data/mnist_png/testing/9/104.png'),Path('/storage/data/mnist_png/testing/9/1045.png'),Path('/storage/data/mnist_png/testing/9/1048.png'),Path('/storage/data/mnist_png/testing/9/105.png'),Path('/storage/data/mnist_png/testing/9/1058.png'),Path('/storage/data/mnist_png/testing/9/1063.png'),Path('/storage/data/mnist_png/testing/9/108.png')...]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "num_cat,num_path,valid_num_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING LONG\n",
    "train_0s = torch.stack([tensor(Image.open(o)) for o in num_path[0]]).float()/255\n",
    "train_1s = torch.stack([tensor(Image.open(o)) for o in num_path[1]]).float()/255\n",
    "train_2s = torch.stack([tensor(Image.open(o)) for o in num_path[2]]).float()/255\n",
    "train_3s = torch.stack([tensor(Image.open(o)) for o in num_path[3]]).float()/255\n",
    "train_4s = torch.stack([tensor(Image.open(o)) for o in num_path[4]]).float()/255\n",
    "train_5s = torch.stack([tensor(Image.open(o)) for o in num_path[5]]).float()/255\n",
    "train_6s = torch.stack([tensor(Image.open(o)) for o in num_path[6]]).float()/255\n",
    "train_7s = torch.stack([tensor(Image.open(o)) for o in num_path[7]]).float()/255\n",
    "train_8s = torch.stack([tensor(Image.open(o)) for o in num_path[8]]).float()/255\n",
    "train_9s = torch.stack([tensor(Image.open(o)) for o in num_path[9]]).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Later consider using Pandas DataFrames as a means of sorting and assigning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING LONG\n",
    "valid_0s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[0]]).float()/255\n",
    "valid_1s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[1]]).float()/255\n",
    "valid_2s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[2]]).float()/255\n",
    "valid_3s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[3]]).float()/255\n",
    "valid_4s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[4]]).float()/255\n",
    "valid_5s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[5]]).float()/255\n",
    "valid_6s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[6]]).float()/255\n",
    "valid_7s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[7]]).float()/255\n",
    "valid_8s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[8]]).float()/255\n",
    "valid_9s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[9]]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5923, 28, 28]), torch.Size([982, 28, 28]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "train_0s.shape, valid_4s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([train_0s, train_1s, train_2s, train_3s, train_4s, train_5s, train_6s, train_7s, train_8s, train_9s]).view(-1, 28*28)\n",
    "train_y = tensor([0]*len(train_0s) + [1]*len(train_1s) + [2]*len(train_2s) + [3]*len(train_3s) + [4]*len(train_4s) + [5]*len(train_5s) + [6]*len(train_6s) + [7]*len(train_7s) + [8]*len(train_8s) + [9]*len(train_9s)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([0]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_0s, valid_1s, valid_2s, valid_3s, valid_4s, valid_5s, valid_6s, valid_7s, valid_8s, valid_9s]).view(-1, 28*28)\n",
    "valid_y = tensor([0]*len(valid_0s) + [1]*len(valid_1s) + [2]*len(valid_2s) + [3]*len(valid_3s) + [4]*len(valid_4s) + [5]*len(valid_5s) + [6]*len(valid_6s) + [7]*len(valid_7s) + [8]*len(valid_8s) + [9]*len(valid_9s)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialise architecture, parameters, loss, metrics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParam(size, std=1.):\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "def mnistModel(inputs):\n",
    "    acts = xb@w1 + b1\n",
    "    acts = acts.max(tensor(0.0))\n",
    "    acts = acts@w2 + b2\n",
    "    return acts\n",
    "\n",
    "def mnistLoss(preds, targs): #softmax to CELoss\n",
    "    sm_preds = torch.log(torch.softmax(preds, dim=1))\n",
    "    idx = range(10)\n",
    "    return sm_preds[idx,targs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnistLoss(preds, yb)\n",
    "    loss.backward()\n",
    "    \n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = initParam((28*28,30))\n",
    "b1 = initParam(30)\n",
    "w2 = initParam((30,1))\n",
    "b2 = initParam(1)\n",
    "lr = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim((w1,b1,w2,b2), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-747471ac3ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnistModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-4601b8f0ca92>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-4601b8f0ca92>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcalc_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-4601b8f0ca92>\u001b[0m in \u001b[0;36mcalc_grad\u001b[0;34m(xb, yb, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnistLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "train_model(mnistModel, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
