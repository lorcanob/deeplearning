{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "import torch\n",
    "\n",
    "fastbook.setup_book()\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *\n",
    "from fastbook import *\n",
    "path = Path('/storage/data/mnist_png')\n",
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('training'),Path('testing')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ingest data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "num_dict = L(enumerate(num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [(0, 'zero'),(1, 'one'),(2, 'two'),(3, 'three'),(4, 'four'),(5, 'five'),(6, 'six'),(7, 'seven'),(8, 'eight'),(9, 'nine')],\n",
       " 'four')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "num_dict, num_dict[4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackNums(train=True):\n",
    "    num_cats = [num_dict[num][1] for num in range(0,10)]\n",
    "    if train==True:\n",
    "        num_path = [(path/'training'/str(num[0])).ls().sorted() for num in num_dict]\n",
    "    else:\n",
    "        num_path = [(path/'testing'/str(num[0])).ls().sorted() for num in num_dict]\n",
    "    return num_cats, num_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat,num_path = stackNums()\n",
    "valid_num_cat,valid_num_path = stackNums(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['zero',\n",
       "  'one',\n",
       "  'two',\n",
       "  'three',\n",
       "  'four',\n",
       "  'five',\n",
       "  'six',\n",
       "  'seven',\n",
       "  'eight',\n",
       "  'nine'],\n",
       " [(#5923) [Path('training/0/1.png'),Path('training/0/1000.png'),Path('training/0/10005.png'),Path('training/0/10010.png'),Path('training/0/10022.png'),Path('training/0/10025.png'),Path('training/0/10026.png'),Path('training/0/10045.png'),Path('training/0/10069.png'),Path('training/0/10071.png')...],\n",
       "  (#6742) [Path('training/1/10006.png'),Path('training/1/10007.png'),Path('training/1/1002.png'),Path('training/1/10020.png'),Path('training/1/10027.png'),Path('training/1/1003.png'),Path('training/1/10040.png'),Path('training/1/10048.png'),Path('training/1/10058.png'),Path('training/1/10067.png')...],\n",
       "  (#5958) [Path('training/2/10009.png'),Path('training/2/10016.png'),Path('training/2/10024.png'),Path('training/2/10029.png'),Path('training/2/10072.png'),Path('training/2/10073.png'),Path('training/2/10075.png'),Path('training/2/10078.png'),Path('training/2/10081.png'),Path('training/2/10082.png')...],\n",
       "  (#6131) [Path('training/3/10.png'),Path('training/3/10000.png'),Path('training/3/10011.png'),Path('training/3/10031.png'),Path('training/3/10034.png'),Path('training/3/10042.png'),Path('training/3/10052.png'),Path('training/3/1007.png'),Path('training/3/10074.png'),Path('training/3/10091.png')...],\n",
       "  (#5842) [Path('training/4/10013.png'),Path('training/4/10018.png'),Path('training/4/10033.png'),Path('training/4/1004.png'),Path('training/4/1006.png'),Path('training/4/10060.png'),Path('training/4/1008.png'),Path('training/4/10103.png'),Path('training/4/10104.png'),Path('training/4/10114.png')...],\n",
       "  (#5421) [Path('training/5/0.png'),Path('training/5/100.png'),Path('training/5/10008.png'),Path('training/5/10015.png'),Path('training/5/10030.png'),Path('training/5/10035.png'),Path('training/5/10049.png'),Path('training/5/10051.png'),Path('training/5/10056.png'),Path('training/5/10062.png')...],\n",
       "  (#5918) [Path('training/6/10017.png'),Path('training/6/10032.png'),Path('training/6/10036.png'),Path('training/6/10037.png'),Path('training/6/10044.png'),Path('training/6/10053.png'),Path('training/6/10076.png'),Path('training/6/10089.png'),Path('training/6/10101.png'),Path('training/6/10108.png')...],\n",
       "  (#6265) [Path('training/7/10002.png'),Path('training/7/1001.png'),Path('training/7/10014.png'),Path('training/7/10019.png'),Path('training/7/10039.png'),Path('training/7/10046.png'),Path('training/7/10050.png'),Path('training/7/10063.png'),Path('training/7/10077.png'),Path('training/7/10086.png')...],\n",
       "  (#5851) [Path('training/8/10001.png'),Path('training/8/10012.png'),Path('training/8/10021.png'),Path('training/8/10041.png'),Path('training/8/10054.png'),Path('training/8/10057.png'),Path('training/8/10061.png'),Path('training/8/10064.png'),Path('training/8/10066.png'),Path('training/8/10079.png')...],\n",
       "  (#5949) [Path('training/9/10003.png'),Path('training/9/10004.png'),Path('training/9/10023.png'),Path('training/9/10028.png'),Path('training/9/10038.png'),Path('training/9/10043.png'),Path('training/9/10047.png'),Path('training/9/1005.png'),Path('training/9/10055.png'),Path('training/9/10059.png')...]],\n",
       " [(#980) [Path('testing/0/10.png'),Path('testing/0/1001.png'),Path('testing/0/1009.png'),Path('testing/0/101.png'),Path('testing/0/1034.png'),Path('testing/0/1047.png'),Path('testing/0/1061.png'),Path('testing/0/1084.png'),Path('testing/0/1094.png'),Path('testing/0/1121.png')...],\n",
       "  (#1135) [Path('testing/1/1004.png'),Path('testing/1/1008.png'),Path('testing/1/1011.png'),Path('testing/1/1019.png'),Path('testing/1/1025.png'),Path('testing/1/1027.png'),Path('testing/1/1030.png'),Path('testing/1/1037.png'),Path('testing/1/1038.png'),Path('testing/1/1040.png')...],\n",
       "  (#1032) [Path('testing/2/1.png'),Path('testing/2/1002.png'),Path('testing/2/1016.png'),Path('testing/2/1031.png'),Path('testing/2/1036.png'),Path('testing/2/1049.png'),Path('testing/2/1050.png'),Path('testing/2/1053.png'),Path('testing/2/1056.png'),Path('testing/2/106.png')...],\n",
       "  (#1010) [Path('testing/3/1020.png'),Path('testing/3/1028.png'),Path('testing/3/1042.png'),Path('testing/3/1062.png'),Path('testing/3/1066.png'),Path('testing/3/1067.png'),Path('testing/3/1069.png'),Path('testing/3/1072.png'),Path('testing/3/1092.png'),Path('testing/3/1095.png')...],\n",
       "  (#982) [Path('testing/4/1010.png'),Path('testing/4/1015.png'),Path('testing/4/1023.png'),Path('testing/4/1024.png'),Path('testing/4/103.png'),Path('testing/4/1043.png'),Path('testing/4/1051.png'),Path('testing/4/1057.png'),Path('testing/4/1059.png'),Path('testing/4/1060.png')...],\n",
       "  (#892) [Path('testing/5/1003.png'),Path('testing/5/102.png'),Path('testing/5/1022.png'),Path('testing/5/1032.png'),Path('testing/5/1041.png'),Path('testing/5/1046.png'),Path('testing/5/1070.png'),Path('testing/5/1073.png'),Path('testing/5/1082.png'),Path('testing/5/1087.png')...],\n",
       "  (#958) [Path('testing/6/100.png'),Path('testing/6/1014.png'),Path('testing/6/1017.png'),Path('testing/6/1035.png'),Path('testing/6/1044.png'),Path('testing/6/1079.png'),Path('testing/6/1085.png'),Path('testing/6/1099.png'),Path('testing/6/11.png'),Path('testing/6/1106.png')...],\n",
       "  (#1028) [Path('testing/7/0.png'),Path('testing/7/1006.png'),Path('testing/7/1012.png'),Path('testing/7/1021.png'),Path('testing/7/1039.png'),Path('testing/7/1055.png'),Path('testing/7/1071.png'),Path('testing/7/1091.png'),Path('testing/7/1096.png'),Path('testing/7/1100.png')...],\n",
       "  (#974) [Path('testing/8/1007.png'),Path('testing/8/1018.png'),Path('testing/8/1026.png'),Path('testing/8/1029.png'),Path('testing/8/1033.png'),Path('testing/8/1052.png'),Path('testing/8/1068.png'),Path('testing/8/1074.png'),Path('testing/8/1093.png'),Path('testing/8/110.png')...],\n",
       "  (#1009) [Path('testing/9/1000.png'),Path('testing/9/1005.png'),Path('testing/9/1013.png'),Path('testing/9/104.png'),Path('testing/9/1045.png'),Path('testing/9/1048.png'),Path('testing/9/105.png'),Path('testing/9/1058.png'),Path('testing/9/1063.png'),Path('testing/9/108.png')...]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "num_cat,num_path,valid_num_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING LONG\n",
    "train_0s = torch.stack([tensor(Image.open(o)) for o in num_path[0]]).float()/255\n",
    "train_1s = torch.stack([tensor(Image.open(o)) for o in num_path[1]]).float()/255\n",
    "train_2s = torch.stack([tensor(Image.open(o)) for o in num_path[2]]).float()/255\n",
    "train_3s = torch.stack([tensor(Image.open(o)) for o in num_path[3]]).float()/255\n",
    "train_4s = torch.stack([tensor(Image.open(o)) for o in num_path[4]]).float()/255\n",
    "train_5s = torch.stack([tensor(Image.open(o)) for o in num_path[5]]).float()/255\n",
    "train_6s = torch.stack([tensor(Image.open(o)) for o in num_path[6]]).float()/255\n",
    "train_7s = torch.stack([tensor(Image.open(o)) for o in num_path[7]]).float()/255\n",
    "train_8s = torch.stack([tensor(Image.open(o)) for o in num_path[8]]).float()/255\n",
    "train_9s = torch.stack([tensor(Image.open(o)) for o in num_path[9]]).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Later consider using Pandas DataFrames as a means of sorting and assigning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING LONG\n",
    "valid_0s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[0]]).float()/255\n",
    "valid_1s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[1]]).float()/255\n",
    "valid_2s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[2]]).float()/255\n",
    "valid_3s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[3]]).float()/255\n",
    "valid_4s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[4]]).float()/255\n",
    "valid_5s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[5]]).float()/255\n",
    "valid_6s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[6]]).float()/255\n",
    "valid_7s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[7]]).float()/255\n",
    "valid_8s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[8]]).float()/255\n",
    "valid_9s = torch.stack([tensor(Image.open(o)) for o in valid_num_path[9]]).float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5923, 28, 28]), torch.Size([1010, 28, 28]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell\n",
    "train_0s.shape, valid_3s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]), torch.Size([60000, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([train_0s, train_1s, train_2s, train_3s, train_4s, train_5s, train_6s, train_7s, train_8s, train_9s]).view(-1, 28*28)\n",
    "train_y = tensor([0]*len(train_0s) + [1]*len(train_1s) + [2]*len(train_2s) + [3]*len(train_3s) + [4]*len(train_4s) + [5]*len(train_5s) + [6]*len(train_6s) + [7]*len(train_7s) + [8]*len(train_8s) + [9]*len(train_9s)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = torch.cat([valid_0s, valid_1s, valid_2s, valid_3s, valid_4s, valid_5s, valid_6s, valid_7s, valid_8s, valid_9s]).view(-1, 28*28)\n",
    "valid_y = tensor([0]*len(valid_0s) + [1]*len(valid_1s) + [2]*len(valid_2s) + [3]*len(valid_3s) + [4]*len(valid_4s) + [5]*len(valid_5s) + [6]*len(valid_6s) + [7]*len(valid_7s) + [8]*len(valid_8s) + [9]*len(valid_9s)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256, shuffle=True)\n",
    "xbOne,ybOne = first(dl)\n",
    "\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "\n",
    "xbOne.shape,ybOne.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define architecture, parameters, loss, metrics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParam(size, std=0.5):\n",
    "    return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "def mnistModel(inputs):\n",
    "    acts = inputs@w1 + b1\n",
    "    acts = acts.max(tensor(0.0))\n",
    "    acts = acts@w2 + b2\n",
    "    return acts\n",
    "\n",
    "def mnistLoss(acts, targs): #softmax to CELoss eventually\n",
    "    sm_preds = -torch.log(torch.softmax(acts, dim=0))\n",
    "    idx = range(sm_preds.size()[0])\n",
    "    loss = sm_preds[idx,targs].mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnistLoss(preds, yb)\n",
    "    loss.backward()\n",
    "    \n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "def batch_accuracy(acts, yb):\n",
    "    sm_preds = -torch.log(torch.softmax(acts, dim=0))\n",
    "    pred_idx = range(sm_preds.size()[0])\n",
    "    correct = [sm_preds[entry].max() == sm_preds[entry,yb[entry]] for entry in pred_idx] #Are these nested indexs a bad idea\n",
    "    return torch.Tensor(correct).float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise parameters and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = initParam((28*28,30))\n",
    "b1 = initParam(30)\n",
    "w2 = initParam((30,10))\n",
    "b2 = initParam(10)\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim((w1,b1,w2,b2), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.095 0.0906 0.0732 0.0703 0.0637 0.0642 0.0607 0.0651 0.0722 0.0609 0.0697 0.0793 0.0683 0.0742 0.0718 0.0769 0.079 0.0835 0.0812 0.0742 "
     ]
    }
   ],
   "source": [
    "train_model(mnistModel, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1172)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test cell\n",
    "acts1 = xbOne@w1 + b1\n",
    "acts2 = acts1.max(tensor(0.0))\n",
    "acts3 = acts2@w2 + b2\n",
    "\n",
    "sm_preds = -torch.log(torch.softmax(acts3, dim=1))\n",
    "pred_idx = range(256)\n",
    "cat_idx = range(10)\n",
    "\n",
    "#Regularise the activations to stop over/underflow\n",
    "#Regularisation/Weight decay can be found in 08_collab\n",
    "\n",
    "#xbOne.size()\n",
    "#acts3.size()\n",
    "#torch.softmax(acts3, dim=0)[29]\n",
    "#torch.log(torch.softmax(acts3, dim=0)).size()[0]\n",
    "\n",
    "#sm_preds[19].long()\n",
    "#correct = torch.Tensor([sm_preds[entry].max() == sm_preds[entry,ybOne[entry]] for entry in pred_idx])\n",
    "correct.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4891,  4.6638,  1.3508,  ...,  3.5009,  0.9014, -1.4019],\n",
       "        [ 1.1965, -4.2717,  1.9960,  ...,  0.7474,  3.4407, -2.1699],\n",
       "        [ 0.9147,  2.2078,  1.6836,  ...,  3.7965,  2.3795, -3.3536],\n",
       "        ...,\n",
       "        [ 0.5149, -0.5262,  2.0887,  ...,  2.7840,  3.6298,  3.6033],\n",
       "        [ 4.0427,  1.4204,  0.4089,  ..., -1.3084,  0.2561, -1.6999],\n",
       "        [ 1.5048,  0.8249,  3.1066,  ...,  4.4098,  2.9789,  2.4687]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test cell\n",
    "#mnist10\n",
    "test_preds = mnistModel(xbOne)\n",
    "\n",
    "#mnistLoss(preds, ybOne).mean()\n",
    "test_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
